install.packages("Rstem")
install.packages("~/Downloads/Rstem_0.4-1.tar.gz", repos = NULL, type = "source")
library(Rstem)
setwd("~/Google Drive/Booth - Spring 2014/Data Mining/Data_Mining_HW_Github/Midterm")
install.packages("SnowballC")
library(Rstem)
library(SnowballC)
ex<-paste(wordStem((strsplit(ex, split=" ")[[1]]), language="english"), collapse=" ")
for (i in 1:nrow(textmatch)){
#PUTS ALL LETTERS IN LOWER CASE
ex<-tolower(gsub("[[:punct:]]", "", textmatch[i,2]))
#REMOVES "STOP WORDS" ("THE", "IT", "AND", "OF", etc.)
ex<-stripWhitespace(removeWords(ex, stopwords("english")))
#STEMS THE REMAINING WORDS
ex<-paste(wordStem((strsplit(ex, split=" ")[[1]]), language="english"), collapse=" ")
#SAVES THE FORMATTED WORDS TO THE THIRD COLUMN
textmatch[i,3]<-ex
print(i)}
OCdata <- read.csv("C:/Users/Mike/Google Drive/Data Mining/finalproject/OCdata.csv")
#BREAK OFF THE TEXT WITH ID CODES
textmatch<-OCdata[,c("IDX", "exp")]
textmatch[,3]<-""
library(tm)
library(SnowballC)
for (i in 1:nrow(textmatch)){
#PUTS ALL LETTERS IN LOWER CASE
ex<-tolower(gsub("[[:punct:]]", "", textmatch[i,2]))
#REMOVES "STOP WORDS" ("THE", "IT", "AND", "OF", etc.)
ex<-stripWhitespace(removeWords(ex, stopwords("english")))
#STEMS THE REMAINING WORDS
ex<-paste(wordStem((strsplit(ex, split=" ")[[1]]), language="english"), collapse=" ")
#SAVES THE FORMATTED WORDS TO THE THIRD COLUMN
textmatch[i,3]<-ex
print(i)}
OCdata <- read.csv("C:/Users/Mike/Google Drive/Data Mining/finalproject/OCdata.csv")
setwd("~/Google Drive/Booth - Spring 2014/Data Mining/Data_Mining_HW_Github/Midterm")
OCdata <- read.csv("OCdata.csv")
#BREAK OFF THE TEXT WITH ID CODES
textmatch<-OCdata[,c("IDX", "exp")]
textmatch[,3]<-""
library(tm)
library(SnowballC)
for (i in 1:nrow(textmatch)){
#PUTS ALL LETTERS IN LOWER CASE
ex<-tolower(gsub("[[:punct:]]", "", textmatch[i,2]))
#REMOVES "STOP WORDS" ("THE", "IT", "AND", "OF", etc.)
ex<-stripWhitespace(removeWords(ex, stopwords("english")))
#STEMS THE REMAINING WORDS
ex<-paste(wordStem((strsplit(ex, split=" ")[[1]]), language="english"), collapse=" ")
#SAVES THE FORMATTED WORDS TO THE THIRD COLUMN
textmatch[i,3]<-ex
print(i)}
ex<-stripWhitespace(removeWords(ex, stopwords("english")))
library(tm)
install.packages("tm")
ex<-stripWhitespace(removeWords(ex, stopwords("english")))
library(tm)
ex<-stripWhitespace(removeWords(ex, stopwords("english")))
for (i in 1:nrow(textmatch)){
#PUTS ALL LETTERS IN LOWER CASE
ex<-tolower(gsub("[[:punct:]]", "", textmatch[i,2]))
#REMOVES "STOP WORDS" ("THE", "IT", "AND", "OF", etc.)
ex<-stripWhitespace(removeWords(ex, stopwords("english")))
#STEMS THE REMAINING WORDS
ex<-paste(wordStem((strsplit(ex, split=" ")[[1]]), language="english"), collapse=" ")
#SAVES THE FORMATTED WORDS TO THE THIRD COLUMN
textmatch[i,3]<-ex
print(i)}
allwords<-""
for (i in 1:nrow(textmatch)){
#ADDS WORDS FROM THIS ROW INTO THE LIST
allwords<-c(allwords, unlist(strsplit(textmatch[i,3], split=" ")))
print(i)}
length(allwords)
WORDS<-unique(allwords)
length(WORDS)
wordct<-matrix(data=NA, nrow=nrow(textmatch), ncol=length(WORDS))
for (i in 1:nrow(textmatch)){
for (j in 1:length(WORDS)){
wordct[i,j]<-sum(unlist(strsplit(textmatch[i,3], split=" "))
==WORDS[j])
}
print(i)}
?sparse
scx=sparse.model.matrix(~.,data=WORDS)[,-1]
library(gamlr)
install.packages("gamlr")
library(gamlr)
scx=sparse.model.matrix(~.,data=WORDS)[,-1]
scx=sparse.model.matrix(~., data=WORDS)[,-1]
scx=sparse.model.matrix(~, data=WORDS)[,-1]
scx=sparse.model.matrix(~., data=wordct)[,-1]
?sparse.model.matrix
wordct<-model.matrix(data=NA, nrow=nrow(textmatch), ncol=length(WORDS))
scx=as.simple_triplet_matrix(wordct)
library(matrix)
library(Matrix)
scx=as.simple_triplet_matrix(wordct)
wordtrip<-matrix(data=NA, nrow=nrow(textmatch)*length(WORDS) ncol=3)
for (i in 1:nrow(textmatch)){
for (j in 1:length(WORDS)){
wordct[i,j]<-sum(unlist(strsplit(textmatch[i,3], split=" "))
==WORDS[j])
TN<-(i-1)+(j-1)*nrow(textmatch)
wordtrip[TN,1]<-i
wordtrip[TN,2]<-j
wordtrip[TN,3]<-wordct[i,j]
}
print(i)}
wordtrip<-matrix(data=NA, nrow=nrow(textmatch)*length(WORDS) ncol=3)
wordtrip<-matrix(data=NA, nrow=nrow(textmatch)*length(W ORDS), ncol=3)
wordtrip<-matrix(data=NA, nrow=nrow(textmatch)*length(WORDS), ncol=3)
for (i in 1:nrow(textmatch)){
for (j in 1:length(WORDS)){
wordct[i,j]<-sum(unlist(strsplit(textmatch[i,3], split=" "))
==WORDS[j])
TN<-(i-1)+(j-1)*nrow(textmatch)
wordtrip[TN,1]<-i
wordtrip[TN,2]<-j
wordtrip[TN,3]<-wordct[i,j]
}
print(i)}
WT<-wordtrip[-which(wordtrip[,3]==0),]
WT<-[-which(is.na(WT[,1])),]
WT<-WT[-which(is.na(WT[,1])),]
wordSM<-sparseMatrix(i=WT[,1],j=WT[,2],x=WT[,3])
reg1= gamlr(wordSM, OCdata$supportOC)
reg1
plot(reg1)
summary(reg1)
coef(reg1)
reg1= cv.gamlr(wordSM, OCdata$supportOC)
plot(reg1)
coef(reg1)
order(coef(reg1))
sort(coef(reg1))
regwords=coef(reg1)
regwords[order(regwords, decreasing=TRUE)[1:10]]
install.packages("textir")
library(textir)
congress109
data(congress109)
?congress109
