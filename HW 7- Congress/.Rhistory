library(parallel)
margreg <- function(p){
fit <- lm(stars~p)
sf <- summary(fit)
return(sf$coef[2,4])
}
#LOAD ALL THE DATA
OCdata <- read.csv("OCdata.csv")
#BREAK OFF THE TEXT WITH ID CODES
textmatch<-OCdata[,c("IDX", "exp")]
textmatch[,3]<-""
library(tm)
library(SnowballC)
for (i in 1:nrow(textmatch)){
#PUTS ALL LETTERS IN LOWER CASE
ex<-tolower(gsub("[[:punct:]]", "", textmatch[i,2]))
#REMOVES "STOP WORDS" ("THE", "IT", "AND", "OF", etc.)
ex<-stripWhitespace(removeWords(ex, stopwords("english")))
#STEMS THE REMAINING WORDS
ex<-paste(wordStem((strsplit(ex, split=" ")[[1]]), language="english"), collapse=" ")
#SAVES THE FORMATTED WORDS TO THE THIRD COLUMN
textmatch[i,3]<-ex
print(i)}
#CREATE A LIST OF EVERY WORD IN EVERY DESCRIPTION
allwords<-""
for (i in 1:nrow(textmatch)){
#ADDS WORDS FROM THIS ROW INTO THE LIST
allwords<-c(allwords, unlist(strsplit(textmatch[i,3], split=" ")))
print(i)}
#NUMBER OF WORDS
length(allwords)
#NUMBER OF UNIQUE WORDS
WORDS<-unique(allwords)
length(WORDS)
#COUNT OF HOW MANY TIMES EACH WORD IS WITHIN EACH DESCRIPTION
wordct<-matrix(data=NA, nrow=nrow(textmatch), ncol=length(WORDS))
wordtrip<-matrix(data=NA, nrow=nrow(textmatch)*length(WORDS), ncol=3)
for (i in 1:nrow(textmatch)){
for (j in 1:length(WORDS)){
wordct[i,j]<-sum(unlist(strsplit(textmatch[i,3], split=" "))
==WORDS[j])
TN<-(i-1)+(j-1)*nrow(textmatch)
wordtrip[TN,1]<-i
wordtrip[TN,2]<-j
wordtrip[TN,3]<-wordct[i,j]
}
print(i)}
fit <- lm(OCdata$supportOC~wordSM)
WT<-wordtrip[-which(wordtrip[,3]==0),]
WT<-WT[-which(is.na(WT[,1])),]
wordSM<-sparseMatrix(i=WT[,1],j=WT[,2],x=WT[,3])
library(gamlr)
fit <- lm(OCdata$supportOC~wordSM)
wordSM<-sparseMatrix(i=WT[,1],j=WT[,2],x=WT[,3])
fit <- lm(OCdata$supportOC~wordSM)
fit <- gamlr(OCdata$supportOC~wordSM)
fit <- gamlr(wordSM,OCdata$supportOC)
sf <- summary(fit)
summary(fit)
plot(fit)
fit <- lm(OCdata$supportOC~wordct)
sf <- summary(fit)
sf
summary(fit)
return(sf$coef[2,4])
xcongress<- scale(congress109Counts)
library(textir)
source("kIC.R")
library(maptpx)
library(gamlr)
data(congress109)
xcongress<- scale(congress109Counts)
kfit <- lapply(1:25, function(k) kmeans(xcongress,k))
source("kIC.R")
kaicc <- sapply(kfit,kIC)
kbic <- sapply(kfit,kIC,"B")
plot(kaicc, xlab="K", ylab="IC",
ylim=range(c(kaicc,kbic)), # get them on same page
bty="n", type="l", lwd=2)
abline(v=which.min(kaicc))
lines(kbic, col=4, lwd=2)
abline(v=which.min(kbic),col=4)
print(which.min(kbic))
k=16
1 - sum(kfit[[k]]$tot.withinss)/kfit[[k]]$totss
setwd("~/Google Drive/Booth - Spring 2014/Data Mining/Data_Mining_HW_Github/HW 7- Congress")
source("kIC.R")
kaicc <- sapply(kfit,kIC)
kbic <- sapply(kfit,kIC,"B")
plot(kaicc, xlab="K", ylab="IC",
ylim=range(c(kaicc,kbic)), # get them on same page
bty="n", type="l", lwd=2)
abline(v=which.min(kaicc))
lines(kbic, col=4, lwd=2)
abline(v=which.min(kbic),col=4)
print(which.min(kbic))
cs <- scale(as.matrix(congress109Counts/rowSums(congress109Counts) ))
klevels<-c(1, 25, 50, 75, 100, 125, 150, 175, 200)
kfit <- lapply(klevels, function(k) kmeans(cs,k))
kaicc <- sapply(kfit,kIC)
kbic <- sapply(kfit,kIC,"B")
plot(kaicc, xlab="K", ylab="IC",
ylim=range(c(kaicc,kbic)),
bty="n", type="l", lwd=2,
xaxt="n")
axis(side=1, at=c(1:length(klevels)), labels=klevels)
abline(v=which.min(kaicc))
lines(kbic, col=4, lwd=2)
abline(v=which.min(kbic),col=4)
kcfit <- lapply(1:25, function(k) kmeans(x,k,nstart=10))
kcbic <- sapply(kcfit,kIC,"B")
## plot 'em
plot(kcbic, xlab="K", ylab="IC",
xlim=c(0,25),ylim=range(kcbic),
bty="n", type="l", lwd=2)
abline(v=which.min(kcbic))
#BIC suggest a model of K=15
x<- scale(congress109Counts) #scale the data
kcfit <- lapply(1:25, function(k) kmeans(x,k,nstart=10))
kcbic <- sapply(kcfit,kIC,"B")
## plot 'em
plot(kcbic, xlab="K", ylab="IC",
xlim=c(0,25),ylim=range(kcbic),
bty="n", type="l", lwd=2)
abline(v=which.min(kcbic))
#BIC suggest a model of K=15
# Data Mining [Matt Taddy]
# HW 7 - Congress
library(textir)
source("kIC.R")
library(maptpx)
library(gamlr)
data(congress109)
x<- scale(congress109Counts) #scale the data
# Averaging by rowsums doesnt work for some reason?
kcfit <- lapply(1:25, function(k) kmeans(x,k,nstart=10))
kcbic <- sapply(kcfit,kIC,"B")
## plot 'em
plot(kcbic, xlab="K", ylab="IC",
xlim=c(0,25),ylim=range(kcbic),
bty="n", type="l", lwd=2)
abline(v=which.min(kcbic))
#BIC suggest a model of K=15
k=15
1 - sum(kcfit[[k]]$tot.withinss)/kcfit[[k]]$totss
print(apply(kcfit[[k]]$centers,1,function(c) colnames(x)[order(-c)[1:10]])) #Cluster 7 is republican
tapply(congress109Ideology$party,kcfit[[k]]$cluster,table)
as.data.frame(tapply(congress109Ideology$party,kcfit[[k]]$cluster,table)
as.data.frame(tapply(congress109Ideology$party,kcfit[[k]]$cluster,table))
as.data.frame(tapply(congress109Ideology$party,kcfit[[k]]$cluster,table))
as.data.frame(a)
a=(tapply(congress109Ideology$party,kcfit[[k]]$cluster,table))
as.data.frame(a)
as.data.frame(a)
print(apply(kcfit[[k]]$centers,1,function(c) colnames(x)[order(-c)[1:10]])) #Cluster 7 is republican
stm <-as.simple_triplet_matrix(congress109Counts) #No clue whyy I'm doing this
tpcs <- topics(stm,K=5*(1:5),tol=10)
summary(tpcs, n=10)
regtopics.cv <- cv.gamlr(tpcs$omega, partisan)
partisan <- congress109Ideology[,"party"]
regtopics.cv <- cv.gamlr(tpcs$omega, partisan)
x <- 100*congress109Counts/rowSums(congress109Counts)
regwords.cv <- cv.gamlr(x, partisan)
par(mfrow=c(1,2))
plot(regtopics.cv)
mtext("topic regression", font=2, line=2)
plot(regwords.cv)
mtext("bigram regression", font=2, line=2)
partisan <- congress109Ideology[,"party"]
tpcreg <- gamlr(tpcs$omega, partisan)
regtopics.cv <- cv.gamlr(tpcs$omega, partisan)
names(congress109$Ideology)
names(congress109Ideology)
names(congress109Ideology$party)
congress109Ideology$party
tpcreg2 <- gamlr(tpcs$omega,congress109Ideology$party)
plot(tpcreg2)
drop(coef(tpcreg))*0.1
?congress109
data(we8there)
stars <- we8thereRatings[,"Overall"]
stars
library(glmnet)
install.packages("glmnet")
library(glmnet)
tpcreg2 <- cv.glmnet(x2, congress109Ideology$party, family="multinomial")
x2<-100*congress109Counts/rowSums(congress109Counts)
tpcreg2 <- cv.glmnet(x2, congress109Ideology$party, family="multinomial")
tpcreg2 <- cv.glmnet(tpcs$omega, congress109Ideology$party, family="multinomial")
plot(tpcsreg2)
plot(tpcreg2)
summary(tpcreg2)
plot(tpcreg2$glm, xvar="lambda")
summary(tpcreg2)
plot(tpcreg2$glm, xvar="lambda")
plot(tpcreg2)
B  <- coef(tpcreg2, select="min")
B
summary(B)
dim(congress109Ideology$party)
length(congress109Ideology$party)
dim(tpcs$omega)
par(mfrow=c(1,1))
plot(tpcreg2)
summary(tpcreg2)
probreg2 <- predict(tpcreg2, tpcs$omega, type="response")
length(tpcs$omega)
trueprobs <- probreg2[cbind(1:length(tpcs$omega), gtype)]
trueprobs <- probreg2[cbind(1:length(tpcs$omega), congress109Ideology$party)]
plot(trueprobs ~ congress109Ideology$party, col="lavender", varwidth=TRUE,
xlab="party", ylab="prob( true class )")
length(tpcreg2)
length(tpcs$omega)
length(congress109Ideology$party)
tpcs <- topics(stm,K=5*(1:5),tol=10)
length(tpcs)
summary(tpcs, n=10)
length(tpcs$omega)
plot(tpcs$omega)
tpcs$omega
length(tpcs$omega)
length(congress109Ideology$repshare)
length(stars)
xs <- as.simple_triplet_matrix(we8thereCounts)
tpcs <- topics(xs,K=5*(1:5),tol=10) # it chooses 10 topics
length(tpcs$omega)
regtopics.cv <- cv.gamlr(tpcs$omega, stars)
x <- 100*we8thereCounts/rowSums(we8thereCounts)
regwords.cv <- cv.gamlr(x, stars)
par(mfrow=c(1,2))
plot(regtopics.cv)
mtext("topic regression", font=2, line=2)
plot(regwords.cv)
mtext("bigram regression", font=2, line=2)
tpcs <- topics(stm,K=5*(1:5),tol=10)
tpcreg2 <- cv.glmnet(tpcs$omega, congress109Ideology$party, family="multinomial")
plot(tpcreg2)
b <- coef(tpcreg2)
b
summary(tpcreg2)
summary(coef(tpcreg2))
dim(coef(tpcreg2))
names(coef(tpcreg2))
as.data.fram(b)
as.data.frame(b)
as.matrix(b)
b[c("D","I","R"),]
b[c("D","I"),]
b[["D"]
]
b[[c("D","I"),]]
b[[c("D","I")]]
b[[("D","I")]]
b[["D"]],b[[I]],b[["R"]]
c(b[["D"]],b[[I]],b[["R"]])
c(b[["D"]],b[["I"]],b[["R"]])
source('~/Google Drive/Booth - Spring 2014/Data Mining/midterm/yelp_start.R', echo=TRUE)
b
summary(tpcs, n=10)
